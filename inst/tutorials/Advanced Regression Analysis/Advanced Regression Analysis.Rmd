---
title: "Advanced Regression Analysis with R"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

nInd<-175
indIDs <-paste0("X", sample(10000:40000, nInd))
nVisits<-rpois(indIDs, 4)
nVisits[which(nVisits == 0)]<-1

cogAbaseline<-rpois(indIDs, 25)
cogBbaseline<-rnorm(indIDs, 8,4)
cogCbaseline<-rnorm(indIDs, 20, 2)
sex<-sample(c("M", "F"), nInd, replace = TRUE, prob = c(0.55, 0.45))
age<-floor(runif(nInd, 20, 60))
intervention<-sample(c("Placebo", "Training"), nInd, replace = TRUE)

visitID<-as.factor(rep(indIDs, nVisits))
visitNum <- unlist(lapply(nVisits, seq))

index<-match(visitID, indIDs)
visitSex<-as.factor(sex[index])
visitAge<-age[index]+visitNum
visitIntervention<-as.factor(intervention[index])

cogA<- floor(cogAbaseline[index] + visitNum * 0.2 + rnorm(length(visitNum), 0,1))

cogB<-cogBbaseline[index] + visitNum * (0.1 + 0.03 * as.numeric(visitSex) + 0.05 * as.numeric(visitIntervention)) + rnorm(length(visitNum), 0, 2) 

cogC<-cogCbaseline[index] + visitNum * (0.1 + 0.003 * as.numeric(visitSex) + 0.001 * as.numeric(visitIntervention)) + rnorm(length(visitNum), 0, 5) 

cogDat<-data.frame("ID" = visitID, "VisitNum" = visitNum, "Age" = visitAge, "Sex" = visitSex, "Intervention" = visitIntervention, "CognitionA" = cogA, "CognitionB" = cogB, "CognitionC" = cogC)

```

## Overview of Workshop

Welcome to Advanced Regression Analysis with R. Our aim is to build on your existing knowledge of regression to fit more complex models that can handle more complicated data sets. In this session you will learn about different types of regression analysis, when to use them and how to interpret the results.

### Introduction to Coding For Reproducible Research

This workshop is offered as part of the [Coding For Reproducible Research Intiative](https://uniexeterrse.github.io/workshop-homepage/). Our ambition is to offer a recurring annual series of workshops open to all staff and students, with opportunities for novices through to more experienced users, to expand their skillsets and position them to confidently perform the informatics research projects in an efficient and reproducible way. A key objective is that the framework we put in place ensures that the workshops delivered are fit for purpose, of a consistent high standard, that delivery is sustainable in the longer term, minimises the workload burden on those who facilitate them and can adapt and expand as new training needs are identified.

Championed by and in partnership with

-   Research Software Engineering group
-   Institute of Data Science and Artificial Intelligence (IDSAI)
-   Researcher Development (Doctoral College and ECRs)
-   Reproducibility Network Institutional Leadership team
-   Exeter Health Analytics Research Network

This workshop, and the others in the series, were put together by a series of working groups formed by researchers from across the University supported by Exeter's Research Software Engineering Group. The programme and workshops are under constant evolution. We appreciate your patience as we develop and test these materials and are grateful for your feedback which is a core component of this process. We also need to maintain accurate records of how many participants we have reached, so ask you to mark your attendance on the collaborative document.

### Workshop format

Today's workshop is led by XX and supported by XX. We are all here because we are passionate about sharing our knowledge and supporting the development of our colleagues. For most of us, this is not a requirement of our current position and we are doing this at the margins of our time.

This workshop is a mixture of statistical theory (don't panic), live demonstrations of R code and exercises for you to complete.

This is a hybrid workshop, please be aware of this, online participants we find that engagement is higher if you are willing to turn your cameras on. There will be a dedicated helper for online participants please, either raise your hand or type any questions into the chat. In person participants you are also able to use the Teams link to join the chat.

Our aim is to be responsive to the needs of the group, both in person and virtual. Therefore, think of the schedule as a guide rather than a strict timetable. We welcome questions and queries as we go along, there are helpers in the room so raise your hand if you need assistance. There is also a dedicated helper for the virtual participants so please raise your virtual hand to attract their attention. In person participants you are welcome to post questions in the Teams chat,if you find this easier than putting your hand up. This will be saved and distributed at the end of the workshop.

We would like to highlight that we have a [code of conduct](https://uniexeterrse.github.io/intro-to-r/code.html) and by attending this workshop you are agreeing to abide by it.

### Pre-requisites

This course will not include an introduction to R, or how to setup and use R or Rstudio. It is assumed you are comfortable coding in R and are familiar with:

-   how to write and execute commands in the R console
-   what type of variables are available in R and how to work with these

We also assume that you are comfortable with:

-   simple linear regression
-   multiple linear regression with categorical, binary or continuous predictor variables
-   logistic regression

If not we recommend that you consult our pre-requisite course **Introductory Regression Analysis with R**.

### Course Notes

This tutorial contains the course notes, example code snippets plus explanations, exercises for you to try with solutions and quiz questions to test your knowledge. Attend a workshop on this topic means there are people on hand to help if you have any questions or issues with the materials. However, these have also been designed such that you should also be able to work through them independently.

You can navigate through the section using the menu on the side.

## Mixed Effects Models

### Why use a mixed effects model?

Standard linear regression models make the assumption that the data used to fit the model are randomly selected from the population. By randomly sampled we mean that all pairs of samples are equally different. There is no reason why knowing the outcome of one sample would make it easier for us to predict the outcome of another sample. This is not always the case, and indeed there are times when we want to use data where their are relationships between the observations or structure to the data. This might be deliberate and part of the study design e.g. family or longitudinal studies, or alternatively it may be a consequence of poor study design or unforeseen recruitment bias.

If we force a standard regression mode with this assumption onto these type of data, we run the risk of our results being biases and the wrong conclusion being made. We could filter our data so that it only contains independent samples, but this seems a bit of waste of valuable data that will contain additional information that could improve the fit of our model. Instead it would be preferable to use a methodology that can appropriately model the underlying structure.

Multi-level models are designed to deal with nested, grouped, clustered or hierarchical data. The structure make be something you are interested in or just something we want to control for. It can be considered as a more complex regression framework to model:

-   structure within data
    -   e.g. patients recruited by different consultants from different clinics across the UK
-   heterogeneity in variance between groups
    -   e.g. post-code specific effects on risk factors for disease
-   individual-level and group-level effects
    -   e.g. weight influenced by genetics and local access to gyms
-   dependencies between observations
    -   e.g. educational attainment at age 18 influenced by educational attainment at age 12

It is also referred to as mixed effects model, hierarchical linear models, random effects models, random coefficients models...

### What is a mixed effects model?

Standard linear regression models, such as the example below, have one level, and can be referred to as single level regression models, whereby all the data is treated as independent observations.

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \varepsilon_{i}$$

Where for observation i:

-   $y_{i}$ is the outcome variable
-   $x_{i}$ is the predictor variable
-   $\beta_{0}$ is the intercept
-   $\beta_{0}$ is the slope coefficient for X
-   $\varepsilon \sim N(0,\sigma^2)$ is the error

Critically all the parameters estimated for this model apply to all observations in the full sample. There is a single intercept, and single slope coefficient for each predictor variable, and ultimately a single error term. In order to model structure in our data set we need to expand this formula and introduce new parameters to represent this grouping effect. We use the variance components model, below, to include a group level influence:

$$y_{ij} = \beta_{0} + u_{j} + \varepsilon_{ij}$$

where for observation i, in group j:

-   $y_{ij}$ represents the value for individual i in group j
-   $\beta_{0}$ is the overall mean
-   $u_{j}$ is the group mean
-   $\varepsilon_{ij}$ is the error for individual i in group j

A multi-level model is the combination of both the single level regression model and variance components model. It can be represents as the two equations above, where each equation represents a different level of the data, i.e. one representing the individual level predictors and one representing the group level predictors (level 2). Alternatively, we can write as a single equation, by substituting the level 2 equation into the level 1 equation:

$$y_{ij} = \beta_{0} + u_{0j} + \beta_{1}x_{ij}  + \varepsilon_{ij}$$

From this we can formula we can see that each group has it's own intercept value ($\beta_{0} + u_{0j}$) but every observation has the same slope coefficient ($\beta_{1}$). We call this a random intercepts model.

### What are fixed and random effects?

Typically when defining or describing to mixed effects models, we consider them to include both fixed and random effects, where variables are assigned to be modeled as either one or the other. Fixed effects assume that the parameter estimates apply to all our observations (i.e. do not depend on j) and we estimate the value of the regression parameters for each variable. The interpretation of these estimated coefficients is as it was in single level regression models.

Instead for variables classified as having random effects, we are assuming that each group within that variable has it's own effect and that across all the groups the distribution of their effects is normal. For random effects we are interested in estimating the variance of the distribution from which the group effects come. Conceptually random effects must be categorical variables.

For a mixed effects model with one fixed effect and one random effect we have four parameters to estimate using our observed data:

-   $\beta_{0}$ (fixed effect)
-   $\beta_{1}$ (fixed effect)
-   $\sigma^{2}_{u}$ (random effect)
-   $\sigma^{2}_{\varepsilon}$ (random effect)


```{r quiz1, echo=FALSE}
quiz(caption = "Questions on mixed effects models",
question("What is the primary advantage of using mixed effects models compared to traditional linear regression?",
  answer("Ability to handle non-linear relationships", message = "This is true of both mixed effects and traditional linear regrssion."),
  answer("Ability to consider multiple variables at the same type", message = "This is true of both mixed effects and traditional linear regrssion."),
  answer("Ability to handle data were observations are related to each other", correct = TRUE),
  answer("Faster computation time", message = "Arguably it's probably slower."),
  allow_retry = TRUE
),
question("What is the difference between a fixed effect and a random effect in a mixed effects model?",
  answer("Fixed effects are constants, while random effects are variables"),
  answer("Fixed effects are systematically related to the outcome, while random effects capture unobserved heterogeneity", correct = TRUE),
  answer("Fixed effects are the variables you are interested in, while random effects are the variables you want to adjust for"),
  answer("Fixed effects are controlled for by the researcher, while random effects are inherent characteristics of the data"),
  allow_retry = TRUE
)
)
```

### Fitting mixed effects models in R

#### The dataset

To enable us to try out some multilevel regression models we have some longitudinal data looking at cognitive performance annually for an intervention study. All individuals have multiple entries, capturing data collected at different assessments over time.For each individual we have a unique identifier code (`ID`). We have the individuals sex, intervention status and years education. We then have a series of columns for the visit data, which includes scores from various cognitive tests `CognitionA`, `CognitionB`, etc as well their age at the time of assessment. We can use the `table()` function to tabulate how many visits each individual had, and then the `summary()` and `hist()` functions to calculate some descriptive statistics and plot a histogram of these data.

```{r}
nVisit<-table(cogDat$ID)
summary(as.numeric(nVisit))

hist(nVisit, main = "", xlab = "nVisits", ylab = "nIndividuals", breaks = c(0:max(nVisit)))
```

We can see that the majority of individuals had more than one visit, with a mean of `r signif(mean(nVisit),3)` and a maximum of `r max(nVisit)` visits.

Given we have multiple observations from the same person we can not use standard regression models and instead we need to use a mixed effects model, as it is likely that an individual's performance at one visit will predict their performance at a second visit.

The functions to fit a multi-level model are not provided with the standard installation of R so we need to install a package which contains the functions we need. Packages are the fundamental units of reproducible R code and are the mechanism to increase R's usability. They include reusable R functions, the documentation that describes how to use them, and optionally sample data and tutorials. The package we will use here is called `lme4`. First we will cover how to install and load a package.

#### Installing and loading packages

There are a number of places R packages can be downloaded from (NB not all packages are available in all locations so the package itself will dictate which method you use to install it). Many older packages are stored on CRAN[<https://cran.r-project.org/web/packages/>]. R provides a function to download such packages `install.packages()` where the name of the package is provided as an argument. Multiple packages can be provided as a vector using the `c()` function. The lme4 package we are interested in, can be installed in this way.

```{r, eval = FALSE}
install.packages("lme4")
```

Alternatively in Rstudio, this can be achieved through the drop-down menus: Tools -\> Install Packages... -\> and the package name can be entered (Figure 1). The end of this document contains additional notes on other ways to install packages.

![Install packages in RStudio via dropdown menus](installPackages.png)

You may get a pop-up window asking you to choose a mirror (this is not overly important but logical to choose a local UK based mirror). When you install a package some text may be printed to the console, some of which won't be in plain English or easily understandable. You may get a warning say cannot write to the default library directory and R will suggest an alternative which you can choose to accept. Ultimately you should get a message saying `package 'lme4' successfully unpacked and MD5 sums checked` indicating the installation has worked, it should also tell you where it has installed the package. This information is not important, as it will automatically install it where R can find it, and you shouldn't need to to look at these files. Packages typically build on functionality from other packages and cannot be successfully installed if any packages it depends on are not installed on your system. By default these should be automatically installed along with the package you want. However errors may arise if the packages are hosted in different places and therefore cannot all be installed using the same command. See the end of this document for other methods to install packages from other repositories.

Once we have installed the package we need to load it. As with all other software you install on a computer, it only needs to be installed once and in future R sessions you just need to load the package as follows. The caveat here is if you update the version of R you are using, as the packages are saved in folders relating to the version of R you are using.

```{r}
library("lme4")

```

From the output you can see that it automatically loads any other packages it is dependent on, in this case the Matrix package.

All packages hosted on CRAN come with a webpage which provides a description of what the package does, details on the version number, who wrote the package and other useful information. All packages also come with a manual which documents all the functions the package contains and some will also have vignettes providing an annotated typical workflow for using the package. These are put together by the package authors and therefore can be variable in how accessible the language is and useful the information is for users. Links to the manual and vignette can be accessed through the package's webpage. The documentation for each function can also be accessed through the help function in R. To fit a mixed effects model we will use the function `lmer`, but before we use it let's see what the help function has to say about it.

```{r, eval = FALSE}
help(lmer)

```

You may need to update the package in the future. `update.packages()` can be run to update all packages on your system. Note that every time you update your version of R, you will likely need to reinstall all your packages.

### Coding a mixed effects model

We are going to model how the performance in cognitive test A, varies over the course of the study. As we have repeated measures for most individuals in our study, we are going to include a random intercept for individual. This means that each individual can have a different baseline performance, and we can look for a common trend in the change in cognitive performance. The key features of our model are

-   `CognitionA` is our outcome or dependent variable.
-   `VisitNum` is the independent variable that captures time in the study. This will be modelled as a fixed effect and is what we are interested in measuring the effect of.
-   `ID` is our random effect, i.e. the variable which groups assessment data from the same individual together.

We can tell R to fit this model as follows using the `lmer` function.

```{r}

model.rand.int<-lmer(CognitionA ~ VisitNum  + (1 | ID), data = cogDat)

```

Fixed effects are included using the standard formula notation as used in linear regression models, with the outcome variable on the left and the predictor on the right separated by a `~`. The `1|` notation is how we specify the inclusion of random intercepts. Unlike standard linear regression, there are choices to be made as to what algorithm to use to derive the parameter estimates from the data you have. This decision is more important if you have a small sample size, in larger sample sizes it shouldn't matter too much. The default behaviour in R is to fit a mixed effects regression model using restricted maximium likelihood (REML), which will given unbiased estimates. We can force R to use maximum likelihood by adding the argument `REML = FALSE`.

### Significance testing in mixed effects regression models

We can extract the statistics in a similar manner to linear regression. First, we can use `summary()` to print a nicely formatted output of some of the results and statistics to the console.

```{r}
summary(model.rand.int)

```

The output is similar to that from a linear regression model, fitted with `lm()` however, you may have noticed that there are no p-values in the co-efficients table. Significance testing in mixed effects models is not as straight forward as it is for linear regression. Our objective for significance testing of the fixed effects is the same as for standard regression, to see if there is a relationship between the predictor variable and the outcome. We do this by seeing sif the data supports the alternative hypothesis that the parameter is non-zero (compared to the null hypothesis that it's value is 0). As they are conceptually the same, test statistics for fixed effects can be calculated in the same way from the estimated value of the parameter divided by it's standard error. To go from a test statistic to a p value we need to know what distribution to use and this is where it gets tricky. This isteh challenge, as it is not obvious what distribution these test statistics should follow, and how many degrees of freedom should be applied. It could be influenced by

-   Number of observations (level 1)
-   Number of groups (level 2)
-   Number of random effects
-   Combination of the above.

So to determine significance we either need to make an approximation or a perform simulation to establish a distribution which we can use to calculate a p-value. For example some methods have been proposed to calculate approximations for the degrees of freedom (e.g. Kenward-Roger, Satterthwaite) such that the t-distribution can be used in a manner similar to standard regression analysis. Crucially though there is no widely accepted method for calculating degrees of freedom exists. The `lme4` package does not calculate p-values for the coefficients on principle [see discussion](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html).

However, for many this is not a satisfactory conclusion, so a second package `lmerTest` has been developed, which if loaded alongside lme4, adds p-values to the above table. It is worthwhile noting thought that, there are multiple methods to calculate p-values, and that might introduce some variation. More importantly the different methods are based on different assumptions and therefore may introduce misleading results if these are not appropriate for your data set.

To use the `lmerTest` functionality, as before we need to install and load this package.

```{r}
library(lmerTest)

```

We then have to refit our mixed effects model for the p-values to be calculated.

```{r}
model.rand.int<-lmer(CognitionA ~ VisitNum  + (1 | ID), data = cogDat)
summary(model.rand.int)

```

We can see from the coefficients table, that R has used the t-distribution to calculate p-values for the fixed effects. By default `lmerTest` uses the Satterwaite approximation to calculate the degrees of freedom for this test (stated at the top of the output, alongside the method for estimating the coefficients). In the results we can see that the `VisitNum` variable is significantly positively associated with the performance in cognitive test A (p = `r signif(summary(model.rand.int)$coefficients["VisitNum",5],2)`). We can interpret the parameter for this variable as we typically would, where the value represents the change in the outcome for one unit increase in this variable, i.e. the change in score for cognitive test A for each extra visit. Specifically, participants had a mean increase in score of `r signif(summary(model.rand.int)$coefficients["VisitNum",1],2)` per visit.

We can also extract information about the variables we fitted as random effects. As described above for these, we are estimating parameters of their distribution and specifically the variance of this distribution. For this model, the variance of the individual intercepts is `r signif(as.data.frame(VarCorr(model.rand.int))[1,"vcov"], 2)`. These are hard to attribute much meaning to, but they represent the width of the distribution that the individual effects come from. A larger number imlies a wider distribution and consequently more variation in the individual effects.

We can also do significance testing of the random effects, to determine if the random intercept is needed. Just because we conceptualize that there should/might be structure in our data doesn't mean that there is or that it's effects are large enough for us to need to model it. Given the complexities of significance testing a fixed effect in a mixed effects model, if we can get away with a simpler regression model, we should favour that.

The principle behind a random effect is that each group needs it's own value taken from a distribution and the effects of the groups can not be represented by a single value (as they would it is was modelled as a fixed effect). Therefore, our null hypothesis (which equates to the random effects not being necessary) requires there to be no distribution of effects, which would occur if the variance of the distribution was 0. The alternative hypothesis (which equates to random effects being necessary) is that there is a distribution and hence it has a non-zero variance. These situations can be represented below.

$$H_{null}: \sigma_{u}^2 = 0$$ $$H_{alternative}: \sigma_{u}^2 \neq 0$$

To determine whether we can reject the null hypothesis, we will use the likelihood ratio test to see if the inclusion of the random effect significantly improves the fit of the model. To make this comparison we need to fit a standard linear model with the same fixed effects terms, but omitting the random effect. We can then use the `anova()` function to calculate the test statistics and perform the comparison with the $\chi^2_{1}$ distribution to calculate a p-value.

```{r}
model.lm<-lm(CognitionA ~ VisitNum, data = cogDat)
anova(model.rand.int, model.lm)

```

You will see in the first line of the output, R first refits the random intercepts model with maximum likelihood so that we can perform the likelihood ratio test. It then proceeds to summarise the statistics of the test and provides the p-value from a $\chi^2_{1}$ distribution, which is significant (P = `r signif(anova(model.rand.int, model.lm)[2,8],2)`). Therefore we can conclude that the addition of a random intercept for individual is an important component of the model. Note if we want a more specific p values than 2.2e-16, we can get that by using the fact that the anova output is a matrix and "slicing" the specific element.

```{r}
anova(model.rand.int, model.lm)[2,8]

```

Note that there is also an inbuilt function to perform a test for significant random effects `ranova()`. Let's try it out.

```{r}

ranova(model.rand.int)
```

Looking at the output, we can see two rows, one for each model and the the number of degrees of freedom for the two models is right. If we just look at the p-value it is the same as when we manually coded the anova therefore we might think that we have performed the same analysis. But on closer inspection we can see the log likelihood values and therefore the test statistic are subtly different. This method is in fact using the likelihood statistics from the model fitted using REML, rather than maximum likelihood which is statistically incorrect. We can confirm this by extracting the log likelihood from our lmer model object (which we fitted using REML rather than ML), rather than refitting using maximum likelihood.

```{r}
## log likelihood of linear model
logLik(model.lm)

## log likelihood of random intercepts model fitted with REML
logLik(model.rand.int)
```

Now in reality the results are essentially the same, and indeed they would have been had we used ML to fit our regression model initially. But it may be preferable to use the `anova()` function to explicitly make the model comparisons, so that you can be confident that you know exactly what methods were used.


*Let's see if the other cogntive tests also change consistenly over time*

Write the R code required, to test using a mixed effects regression model, the following: 

1. Is cognitive test B significantly associated with visit number?
2. Is cognitive test B significantly associated with visit number?

```{r rand-intercept-signif, exercise=TRUE}

```

```{r rand-intercept-signif-solution}
model1<-lmer(CognitionB ~ VisitNum  + (1 | ID), data = cogDat)
summary(model1)

model2<-lmer(CognitionC ~ VisitNum  + (1 | ID), data = cogDat)
summary(model2)
```


### Extracting the results

To pull out specific parts of the output we can then use the `$` or use built in functions. We can use `names()` to get a list of all the elements we can extract from the summary object. NB with a linear regression model we extract results using functions applied to the `lm()` output,(e.g `coef(model.lm)`) here we apply functions to the summary output of the `lmer` model (e.g. `coef(summary(model.rand.int))`).

```{r}
summary(model.rand.int)$coefficients
names(summary(model.rand.int))

```

For example we can extract the variance covariance matrix:

```{r}
vcov(summary(model.rand.int))
```

### Graphical representation of random intercept model

When we fit a regression model we are estimating the parameters of a model we have specified that enables us to characterise the relationship between variables. One way we can understand the nature of the graph is to create a plot of it. Let's do that here to visualise what is happening.

To plot the relationship we need to extract the estimates of the parameters of the regression model for both the fixed and random effects Compare the output of the following two commands.

```{r}
coef(summary(model.rand.int))
lapply(coef(model.rand.int), head)

```

The first command `coef(summary(model.rand.int))` gives us just the fixed effects along with the test statistics and p-values. From these coefficients we can make predictions for the average individual in the study, from which we can make generalised conclusions.

The second command `coef(model.rand.int)` gives us the intercept and slope values for each level of our grouping variable, one per row. We have only extracted this output for the first six individuals, as otherwise it would run on for pages. This data is stored in a list, where each random variable has it's own slot, within which is a matrix of the regression parameters. As we have only one random variable we have only slot in our list, so it perhaps seems an unnecessary complicated structure, but it is designed to anticipate models with multiple random variables. `lapply()` is a efficiency function in R which allows us to perform the same function to each slot of the list. Here we wanted to run the command `head()` to pull out the first 6 rows, so that we could make the output more manageable and get a sense of what the output looked like.

Note that the intercepts vary for each individual but the coefficients for `VisitNum` do not. These individual level intercept are calculated as the overall mean intercept estimate (`r coef(summary(model.rand.int))["(Intercept)","Estimate"]`) added to the estimated individual specific effects. The slope coefficient is taken just from the fixed effect estimate. This is in line with the fact that we fitted a random intercept model. From this output we can make individual level predictions for the individuals in our observed data, which doesn't have much meaning for individuals not in our study.

With these coefficients we can visualise the results

```{r, echo = TRUE, fig.height = 6}
par(mar = c(4,4,1,1))
# extract model coefficients
ind.effects <- coef(model.rand.int)$ID
mean.effects <- coef(summary(model.rand.int))[,"Estimate"]

# create x variable that covers visit numbers
x.sample <- as.matrix(c(0:9))

# predict outcome using individual level coefficients
y.ind <- ind.effects[,1]+ t(x.sample %*% t(as.matrix(ind.effects[,2])))
# predict outcome using overal mean effect coefficients
y.mean <- mean.effects[1] + x.sample * mean.effects[2]

y_lim <-range(y.ind)
plot(x.sample, y.mean, ylim = y_lim, xlab = "Visit Number", ylab = "Cognitive Score")
for(i in 1:nrow(y.ind)){
    lines(x.sample, y.ind[i,], lty = 2, col = "grey")
}
lines(x.sample, y.mean, ylim = y_lim, xlab = "Visit Number", ylab = "Cognitive Score")

```

In this plot each dashed grey line represents an individual, while the black solid line represents the overall mean effect. What we can see is that each line starts at a different height on the y axis curtesy of the individual specific intercepts. All the lines are parallel however. The slope of the line is determined by the slope coefficient for `VisitNum` and as this isn't dependent on the random variable there is no variation across individuals. Hence all the lines changes at the same rate. The solid black line falls approximately in the middle, with approximately half on the individual specific lines above and below. This is due to the mean do the distribution of the individual effects being set to 0. The black line tells us about the average individual, and is what we would use to make predictions about an individual outside of this cohort and describe the effect.

### Assumptions for random intercept model

As with all statistical tests, the ability to calculate estimates of the parameters and perform significance testing relies of assumptions about the data you are using. For mixed effects regression these are:

-   Linear relationship between predictors and outcomes.
-   Constant variance across range of predictor variables (homoscedasticity).
-   Errors at every level are normally distributed.
-   The level 1 and level 2 residuals are uncorrelated.
-   The errors at the highest level are uncorrelated.

### Diagnostic plots

There is no automatic way to produce the diagnostic plots like you can from the linear regression function (`lm`). However we can recreate these plots by extracting the required statistics from the `lmer` model object.

Firstly, we can plot the residuals against the fitted values. In this plot we want the points to be randomly scattered with no evidence of a relationship between the x and y axis. Any evidence of the residuals being related to the fitted values may be indicative of a non-linear relationship between the dependent and independent variables. In this example they look pretty random with no obvious pattern.

```{r, echo = TRUE, fig.height = 6}
# a plot to check the constant standard deviation
plot(fitted(model.rand.int),resid(model.rand.int,type="pearson"),col="blue", xlab = "fitted", ylab = "residuals") 
abline(h=0,lwd=2)
```

Secondly, we will consider the distribution of the residuals. Similar to linear regression, the residuals are assumed to be normally distributed with constant standard deviation. Therefore we can use a QQ plot to assess this (as well as look at the values provided in the summary of the model fit which should be symmetric and have a median \~ 0). With a qq plot (or quantile-quantile plot), we are looking for the points to follow the diagonal line, any deviation indicates that the data are not normally distributed. In this example it looks pretty good.

```{r, echo = TRUE, fig.height = 6}
# normality of the residuals
qqnorm(resid(model.rand.int)) 
qqline(resid(model.rand.int))

```

Thirdly, an assumption specific to mixed effects models is that the random effects are also be normally distributed. Again we can use a qq plot to assess this and it looks good.

```{r, echo = TRUE, fig.height = 6}
# normality of the random intercept estimates
qqnorm(ranef(model.rand.int)$`ID`[,1]) 
qqline(ranef(model.rand.int)$`ID`[,1])
```

### Adding random effects for regression coefficients (random slopes)

As well as individual specific intercepts, perhaps we also think that individuals will have a specific relationship between the predictor and outcome variables. We can incorporate this into our model by including a random slope as well as a random intercept. To do this we need to add more parameters to our random intercept model. The random slopes model takes the form:


$$y_{ij} = \beta_{0} + u_{0j} + (\beta_{1} + u_{1j})x_{ij}  + \varepsilon_{ij}$$


where for observation i, in group j:

* $y_{ij}$ represents the value for individual i in group j
* $\beta_{0}$ is the overall mean
* $u_{0j}$ is the difference between the group mean and the overall mean
* $\beta_{1}$ is the mean slope coefficient (i.e. the effect on Y of a one unit increase in X)
* $u_{1j}$ is the difference between the group slope coefficient and the overall mean slope coefficient
* $\varepsilon_{ij}$ is the error for individual i in group j

As before the group level effects (both intercepts and slope coefficients) are assumed to come from a distribution. Specifically the normal distribution, with a mean of 0 and variance $\Omega_{u}$, where $\Omega_{u}$ is the variance covariance matrix of the group effects. The diagonal elements are the variance of the group intercepts and group slope coefficients, respectively and the off diagonal elements are the covariances between the group intercepts and group slope coefficients.

While we have only introduced one more coefficient to our equation we in fact have two more parameters to estimate, the variance of the group slope coefficients ($\sigma_{u1}^2$), and the covariance ($\sigma_{u01}$) between the group intercepts and group slope coefficients. So in total we have 6 regression parameters to estimate:
* two regression parameters for our fixed effects ($\beta_{0}$, $\beta_{1}$) 
* four variances for the random effects ($\sigma^{2}_{u0}$,$\sigma^{2}_{u1}$,$\sigma^{2}_{u01}$, $\sigma^{2}_{\varepsilon}$).

To speficy a random slopes model in R, we use similar syntax as before. Random effect terms are specified in `()`, with a `|` separating the terms to add random effects for on the left from the grouping variable on the right. We want to fit a random intercept and random coefficient for `VisitNum` so the left hand part of the argument becomes `1 + VisitNum`.

```{r}

model.rand.slope<-lmer(CognitionA ~ VisitNum  + (1 + VisitNum| ID), data = cogDat)
summary(model.rand.slope)

```

The output from the random slopes model is very similar to that from the random intercepts model. The difference is that under the Random effects section, there is an extra row for the random slope, and an extra column for the estimated covariance. We interpret and do hypothesis testing of the fixed effects as we did before. Again in this example, Visit Number is significantly positively correlated with the performance in cognitive test A. More than that the values of fixed effect coefficients are very similar.  

If we look at the estimated parameters for the random effects provided in the summary output we can see that the estimated variance for the random intercepts is `27.234116` and the variance for the random slopes is `0.005471`. While the magnitude of these is quite dramatically different, their values are relative to the values of the coefficients. We can also see that the correlation between an individual's random intercept and random slope is `-0.93`, indicating that individuals with larger intercepts have smaller slopes.

To formally test whether the random slopes for `VisitNum` improve the fit of the model we can use the likelihood ratio test through the `anova()` function. Specifically we want to compare our random slopes model with the random intercepts model which we fitted earlier. Hence we can just run the command

```{r}
anova(model.rand.int, model.rand.slope)

```

This test returns a p-value > 0.05, indicating that the data are consistent with the random slopes having no variance and therefore do not offer an improvement to the model. In this situation, the random slopes model is unnecessarily complex and we can revert to a simpler model.

If our results did suggest that the random slopes model had some value, we could repeat the diagnostic plots from before to check our model assumptions; this time thought we would need to add a fourth plot to check the residuals of the random slope term we estimate for each individual.

```{r}
# a plot to check the constant standard deviation
plot(fitted(model.rand.slope),resid(model.rand.slope,type="pearson"),col="blue", xlab = "fitted", ylab = "residuals") 
abline(h=0,lwd=2)

# normality of the residuals
qqnorm(resid(model.rand.slope)) 
qqline(resid(model.rand.slope))

# normality of the random intercept estimates
qqnorm(ranef(model.rand.slope)$ID[,1]) 
qqline(ranef(model.rand.slope)$ID[,1])

# normality of the random slope estimates
qqnorm(ranef(model.rand.slope)$ID[,2])
qqline(ranef(model.rand.slope)$ID[,2])
```


## Expanding the mixed effects model framework

### Including more fixed effects.

The power of regression is the ability to consider the effect of multiple variable simultaneously. 


### Logisitc mixed regression models

### Significance testing of fixed effects with anova

As with linear regression we can use `anova()` to compare the joint effect of fixed effects. Note that the random effects must be identical and the fixed effects must be nested (i.e. one is a subset of the other). This can only be done if we used the maximum likelhood method (set by including the argument `REML = FALSE`), however if the model was intially fitted with `REML = TRUE`, R will first refit the model with `REML = FALSE` and then perform the anova. Here we will compare our random intercepts model with and without a fixed effect for sex

```{r}
model.rand.int.null<-lmer(CognitionA ~ visitNum  + (1 | ID), data = cogDat)

anova(model.rand.int, model.rand.int.null)

```

We can see the p-value is \> 0.05 then we would conclude that sex does not significantly improve the model inline with the t-test of the fixed effect coefficient.

For more information on reasons why a model might not converge we can look at the documentation for the lmer package.

```{r, eval = FALSE}
?convergence
```

## Regression models with interaction terms

We are going to look at how to code an interaction term in R by extending the multiple linear regression model we fitted in the previous workshop (Contact Day 3). If you recall, we fitted a model to see whether age and sex predict cognitive performance as measured by the general cognitive factor. Here we will add an interaction term between age and sex. To do this we need to add the interaction term to our formula.

```{r, eval=FALSE}

model.int<-lm(GCogPriorDeath ~ Age + Sex + Age*Sex, dat = cogDat)
summary(model.int)

```

From the output above we can see that we have four regression coefficients (one per row). If we apply a p-value threshold of 0.05, we would conclude that age has a significant effect on general cognitive performance, but sex does not. The bottom row contains the result for the interaction, and as with the main effect for sex, we can see that R has appended the name of the contrast category to the name of the interaction. We can see that the interaction is significant with a P-value of `r signif(0.9,3)`. The estimated regression coefficient is `r signif(0.9,3)` which represents the change in the age slope parameter for males. So we would conclude that there is a significant effect of age on general cognition in both sexes but the nature of the relationship is significantly different.

To characterise the sex-specific effects in more detail, we can write two equations from this output, one for males and one for females that represent the sex-specific predictions.

```{r,  echo = FALSE, eval = FALSE}

femaleEq<-paste0("$GCogPriorDeath  = ",signif(coefficients(model.int)[1],3), " + ", signif(coefficients(model.int)[2],3), " * Age$")

maleEq<-paste0("$GCogPriorDeath  = ",signif(coefficients(model.int)[1],3), " + ", signif(coefficients(model.int)[3], 3)," + (", signif(coefficients(model.int)[2],3), "+", signif(coefficients(model.int)[4],3),") * Age = ", 
               signif(sum(coefficients(model.int)[c(1,3)]),3), "+",
               signif(sum(coefficients(model.int)[c(2,4)]),3), " * Age$")

```

For females we have

and for males we have

.

We can see that males have a larger intercept, so cross the y-axis at a higher point indicative of a baseline bigger effect. We can also see that they are associated with a larger magnitude of effect in the same direction as females.

Let's look at a visualisation of these two sex specific regression models, where we will plot two lines one for females and one for males.

```{r, eval = FALSE}

plot(bdr.dat$Age, bdr.dat$GCogPriorDeath, pch = 16, col = c("magenta", "blue")[bdr.dat$Sex], xlab = "Age (years)", ylab = "G", xlim = c(65,100))
legend("topleft", pch = 16, col = c("magenta", "blue"), levels(bdr.dat$Sex))

age<-seq(min(bdr.dat$Age), max(bdr.dat$Age),length.out = 20)
pred.males<-sum(coefficients(model.int)[c(1,3)]) + sum(coefficients(model.int)[c(2,4)])*age

pred.females<-coefficients(model.int)[1] + coefficients(model.int)[2]*age 

lines(age, pred.males, col = "blue")
lines(age, pred.females, col = "magenta")
```

We can see in the scatterplot, that while at age 65, males have a higher cognitive score, as they decrease more rapidly than females (shown by the steeper gradient), they quickly fall below the mean prediction for females at around 67-68 years of age.

#### R coding conventions for interactions

In fact we can write this code more compactly, as R will automatically include the main effects for the two variables as well as the interaction, if we use the `*` to denote which variables we want to model an interaction for. For example, we obtain the same output with the more compact coding here:

```{r, eval = FALSE}

model.int<-lm(GCogPriorDeath ~ Age*Sex, dat = bdr.dat)
summary(model.int)

```

If in fact, we want to include just the interaction without the main effect terms, we can use ":" instead.

For example:

```{r, eval = FALSE}

model.int<-lm(GCogPriorDeath ~ Age:Sex, dat = bdr.dat)
summary(model.int)

```

Because we have omitted the main effect terms, we need two interaction terms to capture the sex specific effects (i.e. we need two regression coefficients to enable us to estimate a female-specific slope and a male-specific slope). When we have age as a main effect, the regression coefficient is equivalent to the "Age:Sexfemale" variable. As shown here

```{r, eval = FALSE}

model.int<-lm(GCogPriorDeath ~ Age + Age:Sex, dat = bdr.dat)
summary(model.int)

```

In general though, it is advisable to have the main effects for each predictor variable as well as the interaction, to ensure that effects are correctly attributed to the right source.

## Additional notes

Take a look at the [lme4 vignette](https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf) for more details on how to specify more complex mixed effect models with this package.

Also this post: <https://rstudio-pubs-static.s3.amazonaws.com/63556_e35cc7e2dfb54a5bb551f3fa4b3ec4ae.html>

Notes on REML here: <http://users.stat.umn.edu/~gary/classes/5303/handouts/REML.pdf>

A common error message when using `lmer()` is

> Error in KhatriRao(sm, t(mm)) : (p \<- ncol(X)) == ncol(Y) is not TRUE

If you get this error, try removing observations with missing data. While `lm()` and `glm()` were good at automatically handling the presence of these lmer throws an arguably confusing error.

R packages can be installed in a number of ways depending on where they are located. In this session we covered installing them directly from CRAN. Here are some other ways.
